/**
 * @file useFormSTT.ts
 * @description Form ëª¨ë“œ STT í›…
 * 
 * ì‚¬ìš©ì ì •ë³´ ì…ë ¥ì„ ìœ„í•œ ìŒì„± ì¸ì‹ í›…ì…ë‹ˆë‹¤.
 * 
 * ë™ì‘ ë°©ì‹:
 * 1. ë§ˆì´í¬ ë²„íŠ¼ ON â†’ ìƒì‹œ ë…¹ìŒ ì‹œì‘ + VAD í™œì„±í™”
 * 2. ìŒì„± ì‹œì‘ ê°ì§€ â†’ ì‹œì‘ ì§€ì  UI í‘œì‹œ
 * 3. ìŒì„± ì¢…ë£Œ ê°ì§€ (ë¬´ìŒ Nì´ˆ) â†’ ì¢…ë£Œ ì§€ì  í‘œì‹œ â†’ API ì „ì†¡
 * 4. Gemini ì •ê·œí™” ê²°ê³¼ ë°˜í™˜
 * 5. ë‹¤ì‹œ VAD ê°ì‹œ ìƒíƒœë¡œ (ë§ˆì´í¬ OFFê¹Œì§€)
 * 
 * @example
 * ```tsx
 * const { 
 *   isActive, 
 *   isSpeaking,
 *   speechMarker,
 *   result,
 *   toggleRecording 
 * } = useFormSTT({
 *   field: "height",
 *   onResult: (data) => setHeight(data.normalized),
 * });
 * 
 * return (
 *   <button onClick={toggleRecording}>
 *     {isActive ? "ğŸ”´ ë…¹ìŒ ì¤‘" : "ğŸ™ï¸ ì‹œì‘"}
 *   </button>
 * );
 * ```
 */

"use client";

import { useState, useCallback, useRef, useEffect } from "react";
import type { FormField, FormSTTResponse } from "./types";
import { transcribeForm } from "@/lib/stt/sttClient";

// ============================================================================
// íƒ€ì… ì •ì˜
// ============================================================================

/**
 * ìŒì„± êµ¬ê°„ ë§ˆì»¤ (ì‹œì‘/ì¢…ë£Œ ì§€ì )
 */
export interface SpeechMarker {
    /** ìŒì„± ì‹œì‘ ì‹œê°„ (ms, ë…¹ìŒ ì‹œì‘ ê¸°ì¤€) */
    startTime: number | null;

    /** ìŒì„± ì¢…ë£Œ ì‹œê°„ (ms, ë…¹ìŒ ì‹œì‘ ê¸°ì¤€) */
    endTime: number | null;

    /** ë…¹ìŒ ì‹œì‘ ì‹œê° (ì ˆëŒ€ ì‹œê°„) */
    recordingStartedAt: number | null;
}

/**
 * useFormSTT ì˜µì…˜
 */
export interface UseFormSTTOptions {
    /** ì…ë ¥ í•„ë“œ íƒ€ì… */
    field: FormField;

    /** ì¸ì‹ ì„±ê³µ ì‹œ ì½œë°± */
    onResult?: (result: FormSTTResponse) => void;

    /** ì—ëŸ¬ ë°œìƒ ì‹œ ì½œë°± */
    onError?: (error: string) => void;

    /** ìŒì„± ì‹œì‘ ê°ì§€ ì‹œ ì½œë°± */
    onSpeechStart?: () => void;

    /** ìŒì„± ì¢…ë£Œ ê°ì§€ ì‹œ ì½œë°± */
    onSpeechEnd?: () => void;

    /** ë¬´ìŒ íŒì • ì‹œê°„ (ms, ê¸°ë³¸ê°’: 1200) */
    silenceThresholdMs?: number;

    /** ë³¼ë¥¨ ì„ê³„ê°’ (0-1, ê¸°ë³¸ê°’: 0.02) */
    volumeThreshold?: number;
}

/**
 * useFormSTT ë°˜í™˜ íƒ€ì…
 */
export interface UseFormSTTReturn {
    /** ë…¹ìŒ í™œì„±í™” ì—¬ë¶€ (ë§ˆì´í¬ ON/OFF) */
    isActive: boolean;

    /** í˜„ì¬ ìŒì„± ê°ì§€ ì¤‘ì¸ì§€ */
    isSpeaking: boolean;

    /** API ì²˜ë¦¬ ì¤‘ì¸ì§€ */
    isProcessing: boolean;

    /** ìŒì„± êµ¬ê°„ ë§ˆì»¤ */
    speechMarker: SpeechMarker;

    /** ë§ˆì§€ë§‰ ì¸ì‹ ê²°ê³¼ */
    result: FormSTTResponse | null;

    /** ë§ˆì§€ë§‰ ì—ëŸ¬ ë©”ì‹œì§€ */
    error: string | null;

    /** ë…¹ìŒ í† ê¸€ (ON â†” OFF) */
    toggleRecording: () => void;

    /** ë…¹ìŒ ì‹œì‘ */
    startRecording: () => void;

    /** ë…¹ìŒ ì¤‘ì§€ */
    stopRecording: () => void;

    /** ê²°ê³¼ ì´ˆê¸°í™” */
    reset: () => void;
}

// ============================================================================
// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
// ============================================================================

/**
 * ì§€ì›ë˜ëŠ” MIME íƒ€ì… ì„ íƒ
 */
function pickMimeType(): string {
    const candidates = ["audio/webm;codecs=opus", "audio/webm", "audio/mp4"];
    for (const type of candidates) {
        if (typeof MediaRecorder !== "undefined" && MediaRecorder.isTypeSupported?.(type)) {
            return type;
        }
    }
    return "";
}

/**
 * ì˜¤ë””ì˜¤ ë²„í¼ì—ì„œ RMS(Root Mean Square) ë³¼ë¥¨ ê³„ì‚°
 * 
 * RMSëŠ” ì‹ í˜¸ì˜ ì‹¤íš¨ê°’ì„ ë‚˜íƒ€ë‚´ë©°, ìŒì„± í™œë™ ê°ì§€ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
 * 
 * @param data - Uint8Array í˜•íƒœì˜ ì˜¤ë””ì˜¤ ë°ì´í„° (0-255)
 * @returns 0-1 ë²”ìœ„ì˜ RMS ê°’
 */
function calculateRMS(data: Uint8Array): number {
    let sum = 0;
    for (let i = 0; i < data.length; i++) {
        // 0-255 ë²”ìœ„ë¥¼ -1~1 ë²”ìœ„ë¡œ ë³€í™˜
        const normalized = (data[i] - 128) / 128;
        sum += normalized * normalized;
    }
    return Math.sqrt(sum / data.length);
}

// ============================================================================
// ë©”ì¸ í›…
// ============================================================================

/**
 * Form ëª¨ë“œ STT í›…
 * 
 * ìƒì‹œ ë…¹ìŒ + VADë¥¼ í†µí•´ ìŒì„± ì‹œì‘/ì¢…ë£Œ ì§€ì ì„ ê°ì§€í•˜ê³ 
 * Gemini APIë¥¼ í†µí•´ ì •ê·œí™”ëœ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
 * 
 * @param options - Form STT ì˜µì…˜
 * @returns Form STT ìƒíƒœ ë° ì œì–´ í•¨ìˆ˜
 */
export function useFormSTT(options: UseFormSTTOptions): UseFormSTTReturn {
    const {
        field,
        onResult,
        onError,
        onSpeechStart,
        onSpeechEnd,
        silenceThresholdMs = 1200,  // 1.2ì´ˆ ë¬´ìŒ ì‹œ ìŒì„± ì¢…ë£Œë¡œ íŒì •
        volumeThreshold = 0.02,     // RMS ì„ê³„ê°’
    } = options;

    // -------------------------------------------------------------------------
    // ìƒíƒœ
    // -------------------------------------------------------------------------

    /** ë…¹ìŒ í™œì„±í™” ì—¬ë¶€ */
    const [isActive, setIsActive] = useState(false);

    /** í˜„ì¬ ìŒì„± ê°ì§€ ì¤‘ */
    const [isSpeaking, setIsSpeaking] = useState(false);

    /** API ì²˜ë¦¬ ì¤‘ */
    const [isProcessing, setIsProcessing] = useState(false);

    /** ìŒì„± êµ¬ê°„ ë§ˆì»¤ */
    const [speechMarker, setSpeechMarker] = useState<SpeechMarker>({
        startTime: null,
        endTime: null,
        recordingStartedAt: null,
    });

    /** ë§ˆì§€ë§‰ ê²°ê³¼ */
    const [result, setResult] = useState<FormSTTResponse | null>(null);

    /** ì—ëŸ¬ ë©”ì‹œì§€ */
    const [error, setError] = useState<string | null>(null);

    // -------------------------------------------------------------------------
    // Refs
    // -------------------------------------------------------------------------

    /** ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ */
    const streamRef = useRef<MediaStream | null>(null);

    /** MediaRecorder */
    const recorderRef = useRef<MediaRecorder | null>(null);

    /** ë…¹ìŒ ì²­í¬ */
    const chunksRef = useRef<BlobPart[]>([]);

    /** AudioContext (VADìš©) */
    const audioCtxRef = useRef<AudioContext | null>(null);

    /** AnalyserNode (ë³¼ë¥¨ ë¶„ì„ìš©) */
    const analyserRef = useRef<AnalyserNode | null>(null);

    /** requestAnimationFrame ID */
    const rafRef = useRef<number | null>(null);

    /** ë¬´ìŒ ì‹œì‘ ì‹œê°„ */
    const silenceStartRef = useRef<number | null>(null);

    /** í˜„ì¬ ìŒì„± ì¤‘ì¸ì§€ (refë¡œ ê´€ë¦¬í•˜ì—¬ í´ë¡œì € ë¬¸ì œ ë°©ì§€) */
    const isSpeakingRef = useRef(false);

    /** ì´ë¯¸ API í˜¸ì¶œ ì¤‘ì¸ì§€ (ì¤‘ë³µ ë°©ì§€) */
    const isProcessingRef = useRef(false);

    /** ë…¹ìŒ ì‹œì‘ ì‹œê° */
    const recordingStartTimeRef = useRef<number | null>(null);

    /** MIME íƒ€ì… */
    const mimeTypeRef = useRef(pickMimeType());

    // -------------------------------------------------------------------------
    // VAD ì •ë¦¬ í•¨ìˆ˜
    // -------------------------------------------------------------------------

    /**
     * VAD ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
     */
    const cleanupVAD = useCallback(() => {
        // requestAnimationFrame ì·¨ì†Œ
        if (rafRef.current) {
            cancelAnimationFrame(rafRef.current);
            rafRef.current = null;
        }

        // AudioContext ì •ë¦¬
        if (audioCtxRef.current) {
            audioCtxRef.current.close().catch(() => { });
            audioCtxRef.current = null;
        }

        analyserRef.current = null;
        silenceStartRef.current = null;
    }, []);

    // -------------------------------------------------------------------------
    // ìŒì„± êµ¬ê°„ ì²˜ë¦¬ (API í˜¸ì¶œ)
    // -------------------------------------------------------------------------

    /**
     * ìŒì„± êµ¬ê°„ì´ ëë‚¬ì„ ë•Œ API í˜¸ì¶œ
     * 
     * @param endTime - ìŒì„± ì¢…ë£Œ ì‹œê°„
     */
    const handleSpeechSegment = useCallback(async (endTime: number) => {
        // ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€
        if (isProcessingRef.current) {
            console.log("[useFormSTT] ì´ë¯¸ ì²˜ë¦¬ ì¤‘, ìŠ¤í‚µ");
            return;
        }

        const recorder = recorderRef.current;
        if (!recorder || recorder.state === "inactive") {
            console.warn("[useFormSTT] í™œì„±í™”ëœ ë…¹ìŒì´ ì—†ìŒ");
            return;
        }

        isProcessingRef.current = true;
        setIsProcessing(true);

        try {
            // MediaRecorder ì¤‘ì§€ â†’ Blob ìƒì„±
            const audioBlob = await new Promise<Blob>((resolve, reject) => {
                const handleStop = () => {
                    try {
                        const blob = new Blob(chunksRef.current, {
                            type: recorder.mimeType || "audio/webm",
                        });
                        console.log(`[useFormSTT] Blob ìƒì„±: ${blob.size} bytes`);
                        resolve(blob);
                    } catch (err) {
                        reject(err);
                    }
                };

                recorder.onstop = handleStop;
                recorder.onerror = (e: any) => reject(e?.error || new Error("ë…¹ìŒ ì˜¤ë¥˜"));

                if (recorder.state !== "inactive") {
                    recorder.stop();
                } else {
                    handleStop();
                }
            });

            // ì¢…ë£Œ ë§ˆì»¤ ì—…ë°ì´íŠ¸
            setSpeechMarker((prev) => ({
                ...prev,
                endTime,
            }));

            onSpeechEnd?.();

            // ìµœì†Œ í¬ê¸° ì²´í¬ (ë„ˆë¬´ ì§§ì€ ë…¹ìŒ í•„í„°ë§)
            if (audioBlob.size < 1000) {
                console.warn("[useFormSTT] ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŒ, ìŠ¤í‚µ");
                setIsProcessing(false);
                isProcessingRef.current = false;
                return;
            }

            // API í˜¸ì¶œ
            console.log(`[useFormSTT] API í˜¸ì¶œ: field=${field}`);
            const response = await transcribeForm(audioBlob, field);

            setResult(response);
            setError(null);
            onResult?.(response);

        } catch (err: any) {
            const errMsg = err?.message || "ìŒì„± ì¸ì‹ ì‹¤íŒ¨";
            console.error("[useFormSTT] ì˜¤ë¥˜:", errMsg);
            setError(errMsg);
            onError?.(errMsg);
        } finally {
            setIsProcessing(false);
            isProcessingRef.current = false;

            // ë…¹ìŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            chunksRef.current = [];
            recorderRef.current = null;
        }
    }, [field, onResult, onError, onSpeechEnd]);

    // -------------------------------------------------------------------------
    // VAD ë£¨í”„ (ë³¼ë¥¨ ë¶„ì„)
    // -------------------------------------------------------------------------

    /**
     * VAD ë¶„ì„ ë£¨í”„ ì‹œì‘
     * 
     * AudioContextì™€ AnalyserNodeë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ
     * ì˜¤ë””ì˜¤ ë³¼ë¥¨ì„ ë¶„ì„í•˜ê³  ìŒì„± ì‹œì‘/ì¢…ë£Œë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
     * 
     * @param stream - ë§ˆì´í¬ ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼
     */
    const startVADLoop = useCallback((stream: MediaStream) => {
        // AudioContext ìƒì„±
        const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
        const audioCtx = new AudioContextClass();
        audioCtxRef.current = audioCtx;

        // iOS ë“±ì—ì„œ suspended ìƒíƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ resume
        if (audioCtx.state === "suspended") {
            audioCtx.resume().catch(() => { });
        }

        // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ì„ AudioContextì— ì—°ê²°
        const source = audioCtx.createMediaStreamSource(stream);
        const analyser = audioCtx.createAnalyser();
        analyser.fftSize = 2048;
        source.connect(analyser);
        analyserRef.current = analyser;

        // ë¶„ì„ìš© ë²„í¼
        const buffer = new Uint8Array(analyser.fftSize);

        /**
         * VAD ë¶„ì„ í‹± í•¨ìˆ˜
         * requestAnimationFrameìœ¼ë¡œ ë°˜ë³µ í˜¸ì¶œë©ë‹ˆë‹¤.
         */
        const tick = () => {
            // ë…¹ìŒì´ ë¹„í™œì„±í™”ë˜ë©´ ì¤‘ì§€
            if (!streamRef.current) {
                return;
            }

            // í˜„ì¬ ì˜¤ë””ì˜¤ ë³¼ë¥¨ ë¶„ì„
            analyser.getByteTimeDomainData(buffer);
            const rms = calculateRMS(buffer);
            const now = performance.now();
            const elapsedMs = recordingStartTimeRef.current
                ? now - recordingStartTimeRef.current
                : 0;

            // ìŒì„± ê°ì§€ ì—¬ë¶€
            const isVoiceDetected = rms > volumeThreshold;

            // ----- ìŒì„± ì‹œì‘ ê°ì§€ -----
            if (isVoiceDetected && !isSpeakingRef.current) {
                console.log(`[useFormSTT] ìŒì„± ì‹œì‘ ê°ì§€ (RMS: ${rms.toFixed(4)})`);
                isSpeakingRef.current = true;
                setIsSpeaking(true);
                silenceStartRef.current = null;

                // ì‹œì‘ ë§ˆì»¤ ì—…ë°ì´íŠ¸
                setSpeechMarker((prev) => ({
                    ...prev,
                    startTime: elapsedMs,
                    endTime: null,
                }));

                onSpeechStart?.();

                // ìƒˆ ë…¹ìŒ ì‹œì‘ (ì´ì „ ì²­í¬ëŠ” VAD ì „ ë²„í¼ë¡œ ìœ ì§€)
                // ì‹¤ì œë¡œëŠ” ê³„ì† ë…¹ìŒ ì¤‘ì´ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬ ë¶ˆí•„ìš”
            }

            // ----- ìŒì„± ì¢…ë£Œ ê°ì§€ (ë¬´ìŒ ì§€ì†) -----
            if (!isVoiceDetected && isSpeakingRef.current) {
                // ë¬´ìŒ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                if (silenceStartRef.current === null) {
                    silenceStartRef.current = now;
                }

                const silenceDuration = now - silenceStartRef.current;

                // ë¬´ìŒì´ ì„ê³„ê°’ ì´ìƒ ì§€ì†ë˜ë©´ ìŒì„± ì¢…ë£Œ
                if (silenceDuration >= silenceThresholdMs) {
                    console.log(`[useFormSTT] ìŒì„± ì¢…ë£Œ ê°ì§€ (ë¬´ìŒ ${silenceDuration.toFixed(0)}ms)`);
                    isSpeakingRef.current = false;
                    setIsSpeaking(false);
                    silenceStartRef.current = null;

                    // ìŒì„± êµ¬ê°„ ì²˜ë¦¬ (API í˜¸ì¶œ)
                    handleSpeechSegment(elapsedMs);

                    // VADëŠ” ê³„ì† ë™ì‘ (ë‹¤ìŒ ìŒì„± ëŒ€ê¸°)
                    // ë‹¨, í˜„ì¬ëŠ” í•œ ë²ˆ ì¸ì‹ í›„ ìƒˆ ë…¹ìŒ ì‹œì‘ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
                    // ì´ ë¡œì§ì€ ì¶”í›„ í™•ì¥ ê°€ëŠ¥
                    return; // ì´ë²ˆ tick ì¢…ë£Œ
                }
            }

            // ìŒì„± ì¤‘ì´ë©´ ë¬´ìŒ ì¹´ìš´í„° ë¦¬ì…‹
            if (isVoiceDetected) {
                silenceStartRef.current = null;
            }

            // ë‹¤ìŒ í”„ë ˆì„ ì˜ˆì•½
            rafRef.current = requestAnimationFrame(tick);
        };

        // VAD ë£¨í”„ ì‹œì‘
        rafRef.current = requestAnimationFrame(tick);
    }, [volumeThreshold, silenceThresholdMs, onSpeechStart, handleSpeechSegment]);

    // -------------------------------------------------------------------------
    // ë…¹ìŒ ì‹œì‘
    // -------------------------------------------------------------------------

    /**
     * ë…¹ìŒ ì‹œì‘ (ë§ˆì´í¬ ON)
     */
    const startRecording = useCallback(async () => {
        if (isActive) {
            console.warn("[useFormSTT] ì´ë¯¸ í™œì„±í™”ë˜ì–´ ìˆìŒ");
            return;
        }

        // ì´ˆê¸°í™”
        setError(null);
        setResult(null);
        setSpeechMarker({
            startTime: null,
            endTime: null,
            recordingStartedAt: Date.now(),
        });
        chunksRef.current = [];
        isSpeakingRef.current = false;
        setIsSpeaking(false);

        try {
            // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
            console.log("[useFormSTT] ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­...");
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                },
            });
            streamRef.current = stream;

            // MediaRecorder ìƒì„±
            const mimeType = mimeTypeRef.current;
            const recorder = new MediaRecorder(stream, mimeType ? { mimeType } : undefined);
            recorderRef.current = recorder;

            // ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì§‘
            recorder.ondataavailable = (e) => {
                if (e.data && e.data.size > 0) {
                    chunksRef.current.push(e.data);
                }
            };

            // ë…¹ìŒ ì‹œì‘
            recorder.start();
            recordingStartTimeRef.current = performance.now();
            setIsActive(true);

            console.log("[useFormSTT] ë…¹ìŒ ì‹œì‘, VAD í™œì„±í™”");

            // VAD ì‹œì‘
            startVADLoop(stream);

        } catch (err: any) {
            const errMsg = err?.message || "ë§ˆì´í¬ ê¶Œí•œì„ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.";
            console.error("[useFormSTT] ì‹œì‘ ì‹¤íŒ¨:", errMsg);
            setError(errMsg);
            onError?.(errMsg);
            setIsActive(false);
        }
    }, [isActive, onError, startVADLoop]);

    // -------------------------------------------------------------------------
    // ë…¹ìŒ ì¤‘ì§€
    // -------------------------------------------------------------------------

    /**
     * ë…¹ìŒ ì¤‘ì§€ (ë§ˆì´í¬ OFF)
     */
    const stopRecording = useCallback(() => {
        console.log("[useFormSTT] ë…¹ìŒ ì¤‘ì§€");

        // VAD ì •ë¦¬
        cleanupVAD();

        // MediaRecorder ì •ë¦¬
        const recorder = recorderRef.current;
        if (recorder && recorder.state !== "inactive") {
            recorder.stop();
        }
        recorderRef.current = null;

        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ (ë§ˆì´í¬ ë„ê¸°)
        streamRef.current?.getTracks().forEach((track) => track.stop());
        streamRef.current = null;

        // ìƒíƒœ ì´ˆê¸°í™”
        setIsActive(false);
        setIsSpeaking(false);
        isSpeakingRef.current = false;
        recordingStartTimeRef.current = null;
        chunksRef.current = [];
    }, [cleanupVAD]);

    // -------------------------------------------------------------------------
    // í† ê¸€
    // -------------------------------------------------------------------------

    /**
     * ë…¹ìŒ í† ê¸€ (ON â†” OFF)
     */
    const toggleRecording = useCallback(() => {
        if (isActive) {
            stopRecording();
        } else {
            startRecording();
        }
    }, [isActive, startRecording, stopRecording]);

    // -------------------------------------------------------------------------
    // ë¦¬ì…‹
    // -------------------------------------------------------------------------

    /**
     * ê²°ê³¼ ë° ìƒíƒœ ì´ˆê¸°í™”
     */
    const reset = useCallback(() => {
        setResult(null);
        setError(null);
        setSpeechMarker({
            startTime: null,
            endTime: null,
            recordingStartedAt: null,
        });
    }, []);

    // -------------------------------------------------------------------------
    // í´ë¦°ì—… (ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ)
    // -------------------------------------------------------------------------

    useEffect(() => {
        return () => {
            cleanupVAD();
            streamRef.current?.getTracks().forEach((track) => track.stop());
            streamRef.current = null;
            recorderRef.current = null;
        };
    }, [cleanupVAD]);

    // -------------------------------------------------------------------------
    // ë°˜í™˜
    // -------------------------------------------------------------------------

    // -------------------------------------------------------------------------
    // ìë™ ì‹œì‘ (ë§ˆìš´íŠ¸ ì‹œ)
    // -------------------------------------------------------------------------
    useEffect(() => {
        // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ìë™ìœ¼ë¡œ ë…¹ìŒ ì‹œì‘
        startRecording();
        
        // ì–¸ë§ˆìš´íŠ¸ ë˜ëŠ” ì¬ì‹œì‘ ì‹œ ì •ë¦¬ ë¡œì§ì€ ê¸°ì¡´ useEffect(line 604)ì—ì„œ ì²˜ë¦¬ë¨
    }, [startRecording]);

    return {
        isActive,
        isSpeaking,
        isProcessing,
        speechMarker,
        result,
        error,
        toggleRecording,
        startRecording,
        stopRecording,
        reset,
    };
}

export default useFormSTT;
